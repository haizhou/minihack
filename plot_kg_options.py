"""
plot_kg_options.py — 绘制 KG-guided Option-PPO 在 MiniHack-KeyRoom-S5 上的学习曲线
从训练日志中提取的完整数据（~1M primitive steps, 6120 episodes）
"""
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker

# ── 训练数据（从终端输出解析）────────────────────────────────────────────────
prim_steps = [
    1782,3392,5177,6960,8421,10150,11483,13123,14936,16851,
    18511,20253,21831,23553,25189,26822,28444,30298,31529,33177,
    34774,36369,38259,40031,41666,43382,45213,46696,48111,49808,
    51808,53290,54888,56737,58211,59594,61331,62831,64149,65720,
    67303,68964,70484,71990,73479,75318,76866,78511,80046,81779,
    83252,84730,86355,88125,89735,91086,92685,94444,96108,97895,
    99246,100820,102626,104183,105953,107288,108896,110600,112192,114003,
    115595,117160,118879,120379,122165,124046,125886,127616,129279,130996,
    132476,134074,135635,137273,138973,140521,141864,143407,145072,146697,
    147832,149277,150719,152581,154210,155866,157476,158973,160800,162364,
    164209,166016,167767,169301,171301,173068,174704,176451,178118,179471,
    181285,182991,184628,186216,187755,189476,191043,192770,194071,195566,
    197129,198616,200432,202133,203537,205290,206850,208276,209676,211527,
    213408,214742,216642,218419,220129,221899,223455,225262,226972,228419,
    230291,232070,233842,235587,237201,238889,240371,242263,243881,245548,
    247137,249076,250779,251946,253424,255039,256955,258761,260129,261831,
    263419,265351,267203,268920,270619,272398,274279,276017,277664,279561,
    281457,283065,284923,286562,288326,290243,292060,293838,295656,297470,
    299324,301063,302879,304799,306416,308314,309781,311400,313068,314645,
    316378,318015,319679,321204,322527,323926,325584,327277,329223,330700,
    332489,334324,335882,337530,339183,340703,342260,343612,345182,346929,
    348648,349921,351868,353453,355109,356736,358228,360208,361869,363414,
    364925,366467,368152,369965,371680,373030,374521,376191,377978,379669,
    381067,382741,384552,386045,387551,389207,390693,392122,393913,395363,
    396523,398089,399797,401202,402975,404478,406070,407862,409339,410943,
    412673,414307,416080,417833,419228,420900,422630,424143,425892,427432,
    429206,430601,432016,433543,435342,436940,438557,440167,441962,443152,
    444908,446508,448262,449701,451566,453204,454573,455841,457544,459319,
    460844,462520,464454,466227,467924,469757,471635,473530,475069,476650,
    478069,479929,481880,483439,485209,486975,488509,490342,491943,493557,
    495314,497119,498915,500835,502360,503889,505638,507162,508869,510554,
    511772,513417,515058,516455,518037,519340,520840,522452,523951,525823,
    527579,529382,530907,532480,534419,536121,537813,539634,541192,542750,
    544253,546037,547716,549302,550991,552682,554440,556357,558092,559786,
    561621,563159,564718,566414,568240,569863,571469,573149,574962,576633,
    578375,580014,581624,583358,584991,586531,588038,589739,591588,593131,
    594977,596699,598394,600079,601668,603401,605205,607081,608814,610013,
    611517,613024,614779,616388,617971,619442,621059,622548,624334,625892,
    627299,629083,630601,632223,633634,635135,636739,638099,639824,641445,
    643252,644804,646492,648298,649976,651656,653408,654968,656443,658089,
    659772,661385,663064,664732,666547,668056,669692,671392,672904,674450,
    676231,677559,679116,680711,682352,684279,686073,687591,689414,690933,
    692666,694209,695851,697191,698676,700176,701826,703504,705361,707113,
    708777,710345,712073,713479,715032,716774,718397,720288,722054,723891,
    725486,727243,728840,730581,732122,733768,735284,736728,738393,740151,
    741519,743378,744906,746698,748405,750117,752071,753929,755606,757221,
    758845,760421,762083,763879,765669,767531,769183,770628,772442,774124,
    775858,777465,779066,780594,782222,784043,785604,787366,788898,790792,
    792385,793724,795228,796607,798023,799713,801305,802925,804397,805568,
    807268,808967,810450,812266,813754,815361,817182,818726,820286,821949,
    823502,825178,826949,828438,830097,831739,833345,835113,836489,838261,
    840185,842027,843603,845159,846931,848924,850753,851785,853287,855098,
    856720,858360,859793,861555,863282,864630,866326,867886,869475,870734,
    872125,873269,874628,876180,878035,879588,881308,882631,883891,884995,
    886417,887877,889228,890754,892297,893664,895055,896339,897754,899388,
    900905,902649,904275,905813,907323,908894,910663,912394,913819,915603,
    917228,918578,920158,921738,923240,924621,926226,927742,929460,931189,
    932681,934402,936086,937492,938656,940405,942034,943848,945563,946981,
    948956,950679,952453,954209,955802,957695,959056,960792,962573,964008,
    965523,967177,969022,970822,972230,974088,975776,977188,978655,980132,
    981716,982981,984453,985889,987515,989179,990349,992006,993904,995706,
    997497,999120,
]

episodes = list(range(10, 10 + 10 * len(prim_steps), 10))

mean_returns = [
    -0.289,0.348,-0.243,-0.127,0.126,0.029,0.566,-0.155,-0.094,-0.472,
    -0.131,-0.239,0.336,-0.291,-0.103,0.549,0.093,-0.491,0.764,0.353,
    -0.086,0.517,-0.336,-0.293,-0.110,-0.087,-0.125,0.295,0.532,-0.288,
    -0.722,0.720,-0.139,-0.171,0.064,0.287,-0.098,0.482,0.130,0.104,
    0.456,-0.127,0.312,0.337,0.259,-0.365,0.460,-0.172,0.500,-0.108,
    0.302,0.273,0.271,-0.341,0.472,0.657,0.255,-0.315,0.039,0.087,
    0.681,0.294,-0.115,0.440,0.075,0.415,0.436,0.087,0.060,-0.171,
    0.269,0.283,0.052,0.684,-0.165,0.212,-0.354,0.043,0.003,-0.355,
    0.198,0.024,0.236,0.028,0.072,0.408,0.654,0.229,0.064,0.221,
    0.814,0.454,0.181,-0.373,0.177,0.279,0.178,0.637,-0.560,0.255,
    -0.386,-0.163,-0.153,0.216,-0.786,-0.205,-0.173,-0.344,-0.052,-0.016,
    -0.341,0.007,0.179,0.042,0.044,-0.170,-0.214,-0.185,0.575,0.030,
    -0.218,0.235,-0.005,-0.004,0.020,-0.386,-0.021,-0.006,0.231,-0.580,
    -0.169,0.604,-0.443,-0.040,-0.222,-0.188,0.023,-0.411,0.199,0.587,
    -0.212,-0.215,-0.237,-0.171,0.006,-0.033,0.214,-0.402,-0.014,0.223,
    0.022,-0.429,-0.420,0.793,0.405,-0.233,-0.434,-0.491,0.365,0.393,
    0.816,-0.651,-0.198,0.186,-0.010,-0.434,-0.207,0.181,-0.268,-0.464,
    -0.624,0.001,-0.243,-0.021,-0.046,-0.252,-0.212,-0.251,-0.230,-0.452,
    -0.506,-0.082,-0.487,-0.459,-0.262,-0.283,0.340,-0.230,-0.039,0.351,
    -0.056,-0.270,-0.030,0.313,0.159,0.127,-0.059,-0.292,-0.680,0.359,
    -0.485,-0.100,-0.053,-0.298,0.122,-0.093,0.336,0.097,-0.296,-0.479,
    -0.315,0.304,-0.726,-0.273,-0.276,-0.275,0.081,-0.507,-0.278,-0.105,
    0.317,0.129,-0.071,-0.303,-0.312,0.134,0.108,-0.303,-0.270,-0.474,
    0.122,-0.344,-0.488,0.344,-0.095,-0.313,-0.102,0.095,-0.522,0.094,
    0.125,-0.299,-0.284,0.315,-0.488,0.311,0.110,-0.310,0.094,0.084,
    -0.318,0.064,-0.525,-0.371,0.092,-0.178,-0.360,0.087,-0.532,0.090,
    -0.500,0.109,0.240,-0.309,-0.541,-0.359,-0.118,0.057,-0.358,0.686,
    -0.335,-0.139,-0.343,-0.129,-0.334,-0.530,0.086,0.257,-0.560,-0.340,
    0.059,0.064,-0.546,-0.320,-0.343,-0.151,-0.567,-0.529,-0.148,-0.159,
    0.267,-0.355,-0.550,-0.157,0.030,-0.549,0.261,-0.337,0.422,-0.140,
    -0.345,0.039,-0.363,-0.560,0.053,-0.161,-0.154,0.253,-0.175,-0.374,
    0.439,-0.174,-0.162,0.249,-0.162,0.445,0.031,0.040,0.029,-0.183,
    -0.579,-0.373,0.002,0.045,-0.583,-0.182,-0.199,-0.179,0.413,0.434,
    0.221,-0.396,-0.177,-0.177,-0.375,-0.182,-0.189,-0.792,-0.202,-0.180,
    -0.585,0.210,0.407,-0.210,-0.607,-0.385,-0.192,-0.390,-0.618,0.003,
    -0.016,-0.211,-0.197,-0.198,-0.013,0.002,-0.016,-0.012,-0.419,-0.012,
    -0.623,-0.422,-0.409,-0.204,-0.002,-0.426,-0.623,-0.227,-0.425,0.613,
    0.391,0.387,-0.231,-0.034,0.176,-0.020,-0.219,0.384,-0.636,-0.220,
    0.170,-0.244,0.176,-0.026,0.181,0.377,-0.026,0.382,-0.244,-0.038,
    -0.644,-0.029,-0.240,-0.641,-0.447,-0.246,-0.444,-0.232,-0.044,-0.248,
    -0.444,-0.442,-0.261,-0.247,-0.260,-0.044,-0.258,-0.462,0.154,-0.049,
    -0.261,0.363,0.347,-0.057,-0.051,-0.671,-0.265,0.143,-0.468,-0.258,
    -0.072,-0.063,-0.063,0.546,0.137,0.344,-0.070,-0.083,-0.677,-0.275,
    -0.271,-0.263,-0.078,0.343,-0.065,-0.276,0.121,-0.475,-0.073,-0.476,
    -0.074,-0.473,0.121,-0.270,0.136,-0.074,-0.059,0.345,-0.278,-0.068,
    0.137,-0.281,0.137,-0.476,-0.273,-0.266,-0.682,-0.278,0.130,-0.070,
    -0.265,-0.063,-0.282,-0.277,-0.071,-0.881,-0.275,0.135,-0.474,-0.273,
    -0.469,-0.078,-0.066,-0.270,-0.275,-0.485,-0.267,-0.476,-0.061,-0.882,
    -0.071,0.345,-0.060,0.340,-0.060,-0.265,-0.271,-0.278,-0.064,0.753,
    -0.472,-0.270,0.135,-0.679,-0.260,-0.069,-0.278,-0.272,-0.064,-0.278,
    -0.067,-0.470,-0.274,-0.267,-0.471,-0.278,-0.304,-0.269,-0.082,-0.478,
    -0.684,-0.685,-0.287,-0.274,-0.480,-0.899,-0.483,0.357,-0.061,-0.678,
    -0.285,-0.269,-0.078,-0.482,-0.504,-0.063,-0.296,-0.279,-0.095,-0.060,
    0.537,0.138,-0.253,-0.067,-0.280,-0.285,-0.071,-0.066,0.333,0.343,
    0.124,-0.061,0.139,-0.275,-0.069,-0.256,-0.056,0.148,-0.059,0.333,
    -0.065,-0.077,-0.070,-0.469,0.137,-0.077,-0.278,-0.073,-0.271,-0.675,
    0.127,-0.060,-0.069,-0.079,-0.271,-0.062,-0.269,-0.298,-0.473,-0.274,
    -0.274,-0.087,-0.495,0.142,0.142,-0.473,-0.473,-0.481,-0.276,-0.056,
    -0.887,-0.474,-0.510,-0.516,-0.477,-0.089,-0.056,-0.473,-0.272,-0.062,
    -0.260,0.129,-0.676,-0.474,-0.057,-0.881,-0.489,-0.099,-0.073,-0.273,
    -0.465,0.135,-0.086,0.131,-0.266,-0.067,0.145,-0.669,-0.879,-0.678,
    -0.477,-0.269,
]

# OpenDoor option counts (cumulative, sampled from log)
opendoor_counts = [
    13,29,36,51,68,84,98,112,130,141,
    169,193,213,255,308,350,381,430,472,502,
    546,593,634,662,699,728,762,781,803,844,
    881,939,985,1040,1087,1144,1186,1242,1284,1333,
    1369,1407,1441,1487,1533,1582,1626,1653,1692,1739,
    1779,1811,1835,1873,1906,1935,1961,1980,2013,2058,
    2102,2139,2184,2226,2263,2309,2362,2406,2441,2480,
    2531,2570,2600,2646,2705,2760,2818,2859,2911,2976,
    3035,3088,3138,3181,3229,3293,3367,3465,3583,3684,
    3743,3814,3882,3976,4056,4132,4226,4312,4403,4495,
    4583,4685,4790,4886,5005,5128,5232,5333,5428,5510,
    5634,5729,5826,5906,5986,6090,6173,6288,6369,6452,
    6555,6651,6786,6904,7002,7115,7218,7307,7398,7535,
    7658,7744,7852,7965,8077,8188,8281,8402,8509,8601,
    8727,8843,8953,9061,9156,9262,9344,9447,9541,9627,
    9714,9811,9921,9991,10089,10185,10308,10418,10487,10566,
    10627,10702,10791,10888,10991,11077,11165,11257,11341,11438,
    11545,11637,11755,11857,11970,12091,12204,12308,12420,12536,
    12644,12748,12856,12974,13064,13176,13264,13360,13456,13549,
    13654,13766,13866,13983,14083,14184,14304,14415,14550,14643,
    14767,14882,14981,15092,15203,15303,15404,15497,15611,15710,
    15816,15893,16025,16125,16245,16352,16445,16585,16686,16799,
    16906,17003,17109,17238,17347,17442,17547,17655,17783,17906,
    17990,18100,18214,18313,18410,18531,18642,18761,18893,18989,
    19084,19190,19315,19424,19550,19661,19769,19891,19992,20114,
    20239,20341,20460,20579,20686,20786,20910,21025,21161,21255,
    21369,21463,21575,21690,21833,21950,22086,22211,22336,22419,
    22539,22663,22796,22912,23053,23170,23271,23367,23487,23611,
    23704,23806,23927,24038,24139,24254,24372,24489,24574,24665,
    24749,24863,24982,25072,25180,25286,25373,25482,25569,25659,
    25735,25801,25875,25946,26009,26082,26143,26199,26257,26305,
    26335,26387,26421,26446,26479,26503,26524,26574,26607,26630,
    26658,26679,26695,26715,26735,26776,26815,26854,26886,26929,
    26959,26988,27028,27064,27101,27123,27146,27169,27193,27204,
    27225,27250,27274,27298,27322,27343,27369,27390,27412,27433,
    27457,27483,27497,27514,27538,27567,27584,27617,27639,27663,
    27692,27714,27732,27761,27786,27821,27857,27895,27926,27954,
    27990,28027,28072,28106,28153,28203,28251,28291,28331,28386,
    28432,28485,28532,28578,28616,28658,28705,28751,28788,28827,
    28874,28933,28984,29036,29070,29118,29158,29186,29223,29254,
    29285,29302,29338,29373,29409,29445,29500,29536,29583,29621,
    29666,29685,29729,29774,29827,29894,29965,30025,30095,30149,
    30214,30270,30334,30385,30450,30501,30566,30619,30660,30695,
    30720,30752,30790,30834,30884,30929,30974,31023,31073,31116,
    31162,31211,31263,31316,31362,31415,31474,31522,31590,31658,
    31716,31797,31864,31956,32033,32100,32152,32206,32260,32312,
    32365,32399,32434,32481,32526,32578,32616,32654,32695,32719,
    32735,32755,32771,32793,32827,32864,32903,32935,32961,32997,
    33035,33065,33102,33151,33188,33237,33273,33313,33360,33405,
    33452,33498,33546,33612,33664,33716,33761,33805,33844,33901,
    33938,33990,34039,34115,34195,34281,34342,34437,34509,34625,
    34752,34865,34961,35070,35206,35351,35479,35543,35641,35764,
    35868,35983,36066,36192,36296,36397,36502,36617,36714,36793,
    36904,36980,37055,37165,37274,37374,37489,37572,37642,37708,
    37776,37857,37940,38030,38125,38190,38277,38362,38450,38549,
    38632,38741,38844,38951,39057,39156,39276,39381,39471,39590,
    39722,39815,39941,40053,40170,40278,40409,40498,40633,40771,
    40876,41003,41115,41219,41298,41426,41529,41658,41776,41883,
    42015,42138,42240,42336,42453,42591,42695,42813,42926,43013,
    43109,43220,43353,43488,43594,43741,43857,43926,44032,44143,
    44256,44345,44437,44548,44675,44796,44866,44994,45137,45249,
    45356,45449,
]

steps_arr    = np.array(prim_steps)
eps_arr      = np.array(episodes[:len(mean_returns)])
returns_arr  = np.array(mean_returns)
opendoor_arr = np.array(opendoor_counts[:len(mean_returns)])

# ── 平滑：50-点滚动平均 ──────────────────────────────────────────────────────
def smooth(x, w=50):
    kernel = np.ones(w) / w
    padded = np.pad(x, (w-1, 0), mode='edge')
    return np.convolve(padded, kernel, mode='valid')

ret_smooth = smooth(returns_arr, w=50)

# ── 每局 OpenDoor 增量（相对频率） ────────────────────────────────────────────
od_delta = np.diff(opendoor_arr, prepend=opendoor_arr[0])
od_smooth = smooth(od_delta.astype(float), w=50)

# ── 绘图 ─────────────────────────────────────────────────────────────────────
fig, axes = plt.subplots(2, 2, figsize=(14, 9))
fig.suptitle(
    "KG-guided Option-PPO on MiniHack-KeyRoom-S5-v0\n"
    "(~1M primitive steps · KG prior: FindKey=1.8, OpenDoor=0.9)",
    fontsize=13, fontweight='bold'
)

# ── (A) 学习曲线：Mean Return vs Episode ──────────────────────────────────────
ax = axes[0, 0]
ax.plot(eps_arr, returns_arr, color='#aec6e8', lw=0.6, alpha=0.5, label='Raw')
ax.plot(eps_arr, ret_smooth,  color='steelblue', lw=2.2, label='Smoothed (w=50)')
ax.axhline(0, color='gray', lw=0.8, ls='--')
ax.axhline(-0.372, color='tomato', lw=1.2, ls=':', label='Final avg −0.372')
ax.set_xlabel("Episode", fontsize=11)
ax.set_ylabel("Mean Return (10-ep window)", fontsize=11)
ax.set_title("(A) Learning Curve — Return vs Episode", fontsize=11)
ax.legend(fontsize=9)
ax.grid(True, alpha=0.3)
ax.set_ylim(-1.1, 1.1)
# 标注早期快速上升段
ax.annotate("Early\nexploration\ngain", xy=(500, 0.3),
            xytext=(1200, 0.7),
            arrowprops=dict(arrowstyle='->', color='steelblue'),
            color='steelblue', fontsize=8.5)

# ── (B) 学习曲线：Mean Return vs Primitive Steps ────────────────────────────
ax = axes[0, 1]
steps_k = steps_arr / 1000
ax.plot(steps_k, returns_arr, color='#f4b8b0', lw=0.6, alpha=0.5, label='Raw')
ax.plot(steps_k, ret_smooth,  color='tomato', lw=2.2, label='Smoothed (w=50)')
ax.axhline(0, color='gray', lw=0.8, ls='--')
ax.set_xlabel("Primitive Steps (×10³)", fontsize=11)
ax.set_ylabel("Mean Return (10-ep window)", fontsize=11)
ax.set_title("(B) Sample Efficiency — Return vs Steps", fontsize=11)
ax.legend(fontsize=9)
ax.grid(True, alpha=0.3)
ax.set_ylim(-1.1, 1.1)

# ── (C) OpenDoor option 使用频率（每局增量，平滑）───────────────────────────
ax = axes[1, 0]
ax.fill_between(eps_arr, od_smooth, alpha=0.35, color='mediumseagreen')
ax.plot(eps_arr, od_smooth, color='green', lw=1.8, label='OpenDoor Δ/ep (smooth)')
ax.set_xlabel("Episode", fontsize=11)
ax.set_ylabel("OpenDoor invocations per episode", fontsize=11)
ax.set_title("(C) OpenDoor Option Usage Over Time", fontsize=11)
ax.legend(fontsize=9)
ax.grid(True, alpha=0.3)
ax.set_ylim(bottom=0)
# 标注转折点 ~ep 850
ax.axvline(8500, color='orange', lw=1.2, ls='--', alpha=0.8)
ax.text(8600, ax.get_ylim()[1]*0.85, "GoToStairs\nplateaus\n~ep 1600",
        fontsize=8, color='darkorange')

# ── (D) 累计 OpenDoor 调用次数 ────────────────────────────────────────────────
ax = axes[1, 1]
ax.plot(eps_arr, opendoor_arr, color='purple', lw=2)
ax.set_xlabel("Episode", fontsize=11)
ax.set_ylabel("Cumulative OpenDoor calls", fontsize=11)
ax.set_title("(D) Cumulative OpenDoor Option Calls", fontsize=11)
ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x/1000:.0f}k'))
ax.grid(True, alpha=0.3)

# 统计框
stats_text = (
    "Final stats (last 20 eps avg):\n"
    "  Mean Return : −0.372\n"
    "  Total eps   : 6120\n"
    "  Prim steps  : ~999k\n"
    "  OpenDoor    : 45,503 calls\n"
    "  FindKey     : 10,547 calls\n"
    "  GoToStairs  :  5,647 calls\n"
    "  PickupItem  :    677 calls\n"
    "  Explore     :     94 calls"
)
ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
        fontsize=8.5, va='top', family='monospace',
        bbox=dict(boxstyle='round,pad=0.5', facecolor='#f0f0f0', alpha=0.9))

plt.tight_layout()
outfile = "kg_options_learning_curve.png"
plt.savefig(outfile, dpi=150, bbox_inches='tight')
print(f"Saved → {outfile}")
plt.show()
